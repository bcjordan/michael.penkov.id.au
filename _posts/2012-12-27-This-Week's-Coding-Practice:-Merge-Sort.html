---           
layout: post
title: This Week's Coding Practice - Merge Sort
date: 2012-12-27 08:45:56 UTC
updated: 2012-12-27 08:45:56 UTC
comments: false
categories: blog
---
 
While sorting algorithms are very important from a programming point of view, they also frequently occur in our daily practical lives. &nbsp;For example, each week, several students in our lab distribute notes that they will present at the weekly seminar. &nbsp;The students distribute the notes independently, they invariably get out of order. &nbsp;How do you put them back in order? &nbsp;It's a sorting problem.<br /><br /><div>One way would be to put the notes in a new pile, represented by a linked list (a simple array is also possible). &nbsp;You'd insert the notes into the pile one by one, making sure each note goes in the appropriate place and does not upset the pre-existing order. &nbsp;What's the overhead for doing things this way? &nbsp;Well, you have to search the pile and insert the new note, which takes $O(n)$&nbsp;<i>if we don't do anything clever</i>. &nbsp;Since you'll be doing that for all n items, the total cost of sorting the notes is $O(n^2)$, which isn't great. &nbsp;In the word of programming, this is known as an&nbsp;<i>insertion sort</i>. &nbsp;You can improve each insertion time by using a <a href="http://mishapenkov.blogspot.jp/2012/12/this-weeks-coding-practice-binary.html">binary search tree</a>&nbsp;to represent the pile. &nbsp;This is known as a tree sort, and decreases the search and total sort time to $O(\log(n))$ and $O(n \log(n))$, respectively. &nbsp;An auto-balancing BST works best, since in that case even the worst sort time is $O(n \log(n))$.</div><div><br /></div><div>If you want $O(n \log(n))$ sort performance, but don't feel like mentally implementing an auto-balancing BST to sort a couple of notes, there are some alternatives. &nbsp;My personal favorite is merge sort, which, incidentally, is this week's topic. &nbsp;Merge sort is a divide-and-conquer algorithm that is best defined recursively: divide the items into two equally-sized piles, recursively sort each pile, then merge the sorted piles back together. &nbsp;The recursion terminates when a pile cannot be divided any further (i.e. contains less than two elements). &nbsp;What's the computational complexity of merge sort? &nbsp;Since you halve the input array at each recursion depth, the total depth of recursion is $\lceil \log_2(n) \rceil$. &nbsp;At each recursion depth, you also have to merge two sorted piles -- this can be done in linear time. &nbsp;The overall sort thus takes $O(n \log(n))$ (since we don't care about the base of the logarithm).<br /><br />This week's problem was to implement the merge step&nbsp;of the merge sort. &nbsp;To make things more interesting, we're merging an arbitrary number of piles of arbitrary size, instead of two piles of roughly the same size. &nbsp;Here it is, in Python (for a change):<br /><br /><script src="https://gist.github.com/4372560.js"></script> Since I just couldn't help myself, I went ahead and implemented the entire merge sort in Python. &nbsp;It doesn't share any code with the merge step mentioned above, but the principles are the same.<br /><br /></div><div><script src="https://gist.github.com/4385791.js"></script> I'm using a temporary list to perform the merging. &nbsp;It's possible to perform an <i>in-place</i>&nbsp;merge sort without requiring such temporary storage, but I haven't gotten around to it yet.</div><div></div>
